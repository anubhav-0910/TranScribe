# Transformer Model from Scratch
This repository contains transformer model that we bulit from scratch from mathematical level on the basis of “Attention Is All You Need” is a research paper by Ashish Vaswani et al. that proposes a new neural network architecture for sequence-to-sequence tasks.

## Dataset Description
* We have taken English and Hindi paralel corpus dataset of of size 1.94GB and it contains corpus has 49.6M sentence pairs between English to Hindi from AI4BHARAT SAMANANTAR.
* AI4Bharat is a non-profit, open-source community of engineers, domain experts, policy makers and academicians, all collaborating to build AI solutions for solving India’s critical socio-economic and environmental challenges.  It is a research lab at IIT Madras which works on developing open-source datasets, tools, models and applications for Indian languages. 
This initiative is helmed by IIT Madras faculty members Mitesh Khapra and Pratyush Kumar, as a part of their technology startup One Fourth Labs.
* The dataset can be found here in this [link](https://drive.google.com/drive/folders/1in3o1e7IkFm9OcQCh3yCOTwDuxgmvesz?usp=sharing)

## Overview of architecture
![Transformer model](https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png)

## Usage

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/your-repo.git
cd your-repo
```
